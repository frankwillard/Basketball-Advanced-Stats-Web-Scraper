{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Web Scraper",
      "provenance": [],
      "authorship_tag": "ABX9TyMtsA8RMCZ2l5Q1KegCyFog",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankwillard/Basketball-Advanced-Stats-Web-Scraper/blob/main/Final_Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL67RYudI43o"
      },
      "outputs": [],
      "source": [
        "# import needed libraries\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_items(test_list, item):\n",
        "      \n",
        "    # using list comprehension to perform the task\n",
        "    res = [i for i in test_list if i != item]\n",
        "  \n",
        "    return res"
      ],
      "metadata": {
        "id": "q6AgcG13JJQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_replace(string, rep_dict):\n",
        "    pattern = re.compile(\"|\".join([re.escape(k) for k in sorted(rep_dict,key=len,reverse=True)]), flags=re.DOTALL)\n",
        "    return pattern.sub(lambda x: rep_dict[x.group(0)], string)"
      ],
      "metadata": {
        "id": "CvlWKWItNXJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to scrape team performance for multiple years\n",
        "def scrape_NBA_team_data(years = [2017, 2018]):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Team', 'Age', 'W', 'L', 'PW', 'PL', 'MOV', 'SOS', 'SRS',\n",
        "       'ORtg', 'DRtg', 'NRtg', 'Pace', 'FTr', '3PAr', 'TS%', 'OeFG%', 'OTOV%',\n",
        "       'ORB%', 'OFT/FGA', 'DeFG%', 'DTOV%', 'DRB%', 'DFT/FGA', 'Arena', 'Attend.',\n",
        "       'Playoffs', 'W/L%', 'Losing_season'])\n",
        "\n",
        "    # loop through each year\n",
        "    for y in years:\n",
        "        # NBA season to scrape\n",
        "        year = y\n",
        "        \n",
        "        # URL to scrape, notice f string:\n",
        "        url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
        "        \n",
        "        # collect HTML data\n",
        "        html = urlopen(url)\n",
        "        \n",
        "        # create beautiful soup object from HTML\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "        league_champ_txt = soup.findAll(\"strong\")[1]\n",
        "\n",
        "        league_champ = league_champ_txt.find_next_sibling(\"a\").getText()\n",
        "\n",
        "\n",
        "        #rows = adv_table.tbody.find_all('tr')\n",
        "        \n",
        "        adv_table = soup.find(id='advanced-team')\n",
        "\n",
        "        adv_cols = [th.getText() for th in adv_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        adv_cols = remove_items(adv_cols, '\\xa0')\n",
        "        adv_cols.remove('Attend./G')\n",
        "\n",
        "        for i in [17,18,20]:\n",
        "          adv_cols[i]=\"O\"+adv_cols[i]\n",
        "        \n",
        "        for i in [21,22,24]:\n",
        "          adv_cols[i]=\"D\"+adv_cols[i]\n",
        "\n",
        "        #df = pd.DataFrame(columns=[\"Year\"].extend(adv_cols))\n",
        "\n",
        "        reg_dict = {\n",
        "            \"+\":\"\",\n",
        "            \",\":\"\"\n",
        "        }\n",
        "        \n",
        "        team_stats = []\n",
        "        j = 0\n",
        "\n",
        "        rows = adv_table.tbody.find_all('tr')\n",
        "        for row in rows:\n",
        "          columns = row.find_all('td')\n",
        "          team_stats.append([multiple_replace(columns[i].getText(), reg_dict) for i in range(len(columns)-1) if columns[i].getText() != ''])\n",
        "          # remove empty elements\n",
        "          #team_stats = [e for e in team_stats if e != []]\n",
        "          \n",
        "          # add team name to each row in team_stats\n",
        "        for i in range(0, len(team_stats)):\n",
        "            team_stats[i].insert(0, year)\n",
        "        \n",
        "        # add team, year columns to headers\n",
        "        adv_cols.insert(0, \"Year\")\n",
        "\n",
        "        adv_cols.remove(\"Rk\")\n",
        "        \n",
        "        # create a dataframe with all aquired info\n",
        "        year_standings = pd.DataFrame(team_stats, columns = adv_cols)        \n",
        "        # add a column to dataframe to indicate playoff appearance\n",
        "        # remove * from team names\n",
        "        year_standings[\"Team\"] = [ele.replace('*', '') for ele in year_standings[\"Team\"]]\n",
        "\n",
        "        for col in year_standings.columns:\n",
        "          if col != \"Team\" and col != \"Arena\":\n",
        "            year_standings[col] = year_standings[col].astype(float)\n",
        "        \n",
        "        year_standings[\"Playoffs\"] = [\"Y\" if \"*\" in ele else \"N\" for ele in year_standings[\"Team\"]]\n",
        "\n",
        "        # add losing season indicator (win % < .5)\n",
        "        year_standings[\"W/L%\"] = year_standings[\"W\"] / (year_standings[\"W\"] + year_standings[\"L\"])\n",
        "\n",
        "        year_standings[\"Losing_season\"] = [\"Y\" if float(ele) < .5 else \"N\" for ele in year_standings[\"W/L%\"]]\n",
        "\n",
        "        year_standings[\"Champion\"] = [\"Y\" if name == league_champ else \"N\" for name in year_standings[\"Team\"]]\n",
        "        \n",
        "        #for i in [17,18,20]:\n",
        "        #  year_standings = year_standings.rename(columns={year_standings.columns[i]: 'O'+year_standings.columns[i]})\n",
        "        \n",
        "        #for i in [21,22,25]:\n",
        "        #  year_standings = year_standings.rename(columns={year_standings.columns[i]: 'D'+year_standings.columns[i]})\n",
        "\n",
        "        #print(year_standings.columns)\n",
        "\n",
        "        # append new dataframe to final_df\n",
        "        final_df = final_df.append(year_standings)\n",
        "    \n",
        "\n",
        "    lag_1 = final_df['Champion'].shift(1)\n",
        "\n",
        "    final_df['won_last'] = lag_1  # add to DataFrame\n",
        "\n",
        "    concat = final_df['Champion'].shift(1) + final_df['Champion'].shift(2) + final_df['Champion'].shift(3)\n",
        "\n",
        "    lag_3 = concat.str.contains(\"Y\")\n",
        "\n",
        "    final_df['won_last_3'] = [\"Y\" if lagger == \"Y\" else \"N\" for lagger in lag_3]  # add to DataFrame\n",
        "    \n",
        "    final_df = final_df[final_df.Year > 1989.0]\n",
        "\n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    # export to csv\n",
        "    final_df.to_csv(\"nba_team_advanced_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "TKsLs_uiI5yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_NBA_team_data(years = [1990])"
      ],
      "metadata": {
        "id": "rInFgJvigKI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_NBA_team_data(years = [1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994,\n",
        "                              1995, 1996, 1997, 1998, 1999,\n",
        "                              2000, 2001, 2002, 2003, 2004,\n",
        "                              2005, 2006, 2007, 2008, 2009,\n",
        "                              2010, 2011, 2012, 2013, 2014,\n",
        "                              2015, 2016, 2017, 2018, 2019,\n",
        "                              2020])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNg8Y-nRI7gh",
        "outputId": "b14bc8f0-16aa-4037-97c0-042d19592ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.info of       Year                    Team   Age  ...  Champion  won_last  won_last_3\n",
            "0   1990.0      Los Angeles Lakers  28.9  ...         N         N           N\n",
            "1   1990.0            Phoenix Suns  26.7  ...         N         N           N\n",
            "2   1990.0         Detroit Pistons  29.5  ...         Y         N           N\n",
            "3   1990.0  Portland Trail Blazers  26.7  ...         N         Y           N\n",
            "4   1990.0      Philadelphia 76ers  27.4  ...         N         N           N\n",
            "..     ...                     ...   ...  ...       ...       ...         ...\n",
            "25  2020.0         New York Knicks  24.5  ...         N         N           N\n",
            "26  2020.0       Charlotte Hornets  24.3  ...         N         N           N\n",
            "27  2020.0           Atlanta Hawks  24.1  ...         N         N           N\n",
            "28  2020.0     Cleveland Cavaliers  25.0  ...         N         N           N\n",
            "29  2020.0   Golden State Warriors  24.4  ...         N         N           N\n",
            "\n",
            "[903 rows x 33 columns]>\n"
          ]
        }
      ]
    }
  ]
}